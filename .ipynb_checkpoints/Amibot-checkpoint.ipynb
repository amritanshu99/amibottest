{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c4703d-9222-4575-bfac-9347f95ae6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\amrit\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\amrit\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\amrit\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\amrit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\amrit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¥ Loading transformer model...\n",
      "âœ… Loaded CSV with encoding: Index(['Field', 'Value'], dtype='object')\n",
      "ğŸ’¾ Saved df.pkl, field_variants.pkl, and field_embeddings.pt to 'amibot_data/'\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Ask AmiBot (type 'exit' to quit):  Hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Matched: 'hi'\n",
      "ğŸ“ Semantic: 0.64, ğŸ”¤ Fuzzy: 100.0\n",
      "ğŸ‘‰ Hi there! Youâ€™re now talking to AmiBot â€” the digital soul of Amritanshu Mishra. Ask anything about him, and letâ€™s explore his world together!\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“¦ Install required packages (run once)\n",
    "!pip install -q sentence-transformers rapidfuzz nltk\n",
    "\n",
    "# ğŸ“¥ Imports\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from rapidfuzz import fuzz\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "import re\n",
    "import torch\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# ğŸ“Œ Download NLTK corpus\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# ğŸ§  Load transformer model\n",
    "print(\"ğŸ“¥ Loading transformer model...\")\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# ğŸ“„ Load your CSV file (replace path if needed)\n",
    "csv_path = \"amibot.csv\"  # Ensure it has columns: 'Field', 'Value'\n",
    "try:\n",
    "    df = pd.read_csv(csv_path, encoding='utf-8')\n",
    "except UnicodeDecodeError:\n",
    "    df = pd.read_csv(csv_path, encoding='cp1252')  # fallback encoding\n",
    "\n",
    "print(\"âœ… Loaded CSV with encoding:\", df.columns)\n",
    "\n",
    "# ğŸ“š Preprocess data\n",
    "field_variants = []\n",
    "field_map = {}\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    field_str = row[\"Field\"]\n",
    "    value = row[\"Value\"]\n",
    "    variants = [v.strip().lower() for v in field_str.split(\",\") if v.strip()]\n",
    "    for v in variants:\n",
    "        field_variants.append(v)\n",
    "        field_map[v] = value  # Map each variant to its value\n",
    "\n",
    "field_embeddings = model.encode(field_variants, convert_to_tensor=True)\n",
    "\n",
    "# ğŸ”§ Function: Correct typos (basic spell fix using regex for now)\n",
    "def correct_typos(text):\n",
    "    text = text.strip().lower()\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    return text\n",
    "\n",
    "# ğŸ”§ Function: Expand with synonyms using WordNet\n",
    "def expand_with_synonyms(text):\n",
    "    words = text.split()\n",
    "    expanded_words = []\n",
    "    for word in words:\n",
    "        synonyms = set()\n",
    "        for syn in wordnet.synsets(word):\n",
    "            for lemma in syn.lemmas():\n",
    "                synonyms.add(lemma.name().replace(\"_\", \" \"))\n",
    "        if synonyms:\n",
    "            expanded_words.append(word + \" \" + \" \".join(list(synonyms)[:2]))\n",
    "        else:\n",
    "            expanded_words.append(word)\n",
    "    return \" \".join(expanded_words)\n",
    "\n",
    "# ğŸ¤– Function: Get AmiBot response\n",
    "def get_response(user_input, model, field_variants, field_embeddings, field_map, threshold=0.55, fuzz_threshold=55):\n",
    "    original_input = user_input.strip()\n",
    "    corrected_input = correct_typos(original_input)\n",
    "    expanded_input = expand_with_synonyms(corrected_input)\n",
    "\n",
    "    query_embedding = model.encode(expanded_input, convert_to_tensor=True)\n",
    "    similarities = util.cos_sim(query_embedding, field_embeddings)[0]\n",
    "\n",
    "    best_score = float(similarities.max())\n",
    "    best_idx = int(similarities.argmax())\n",
    "    best_field = field_variants[best_idx]\n",
    "    best_answer = field_map[best_field]\n",
    "\n",
    "    fuzzy_score = fuzz.token_set_ratio(original_input.lower(), best_field.lower())\n",
    "\n",
    "    if best_score >= threshold or fuzzy_score >= fuzz_threshold:\n",
    "        return f\"\\nâœ… Matched: '{best_field}'\\nğŸ“ Semantic: {best_score:.2f}, ğŸ”¤ Fuzzy: {fuzzy_score}\\nğŸ‘‰ {best_answer}\"\n",
    "    else:\n",
    "        return f\"\\nğŸ¤– Sorry, Iâ€™m not sure what you meant.\\nğŸ’¡ Did you mean: '{best_field}'?\\nPlease rephrase your question.\"\n",
    "\n",
    "# ğŸ’¾ Save necessary components for Flask app\n",
    "save_dir = \"amibot_data\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "with open(f\"{save_dir}/df.pkl\", \"wb\") as f:\n",
    "    pickle.dump(df, f)\n",
    "\n",
    "with open(f\"{save_dir}/field_variants.pkl\", \"wb\") as f:\n",
    "    pickle.dump(field_variants, f)\n",
    "\n",
    "with open(f\"{save_dir}/field_map.pkl\", \"wb\") as f:\n",
    "    pickle.dump(field_map, f)\n",
    "\n",
    "torch.save(field_embeddings, f\"{save_dir}/field_embeddings.pt\")\n",
    "\n",
    "print(\"ğŸ’¾ Saved df.pkl, field_variants.pkl, and field_embeddings.pt to 'amibot_data/'\")\n",
    "\n",
    "# ğŸ§ª Test in Notebook (example)\n",
    "while True:\n",
    "    user_input = input(\"\\nAsk AmiBot (type 'exit' to quit): \")\n",
    "    if user_input.lower() == \"exit\":\n",
    "        break\n",
    "    response = get_response(user_input, model, field_variants, field_embeddings, field_map)\n",
    "    print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4c90978-973d-412f-a4c7-9dffc42cb2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Install & Import Packages\n",
    "# !pip install -q sentence-transformers rapidfuzz nltk\n",
    "# Load the Transformer Model\n",
    "# model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "# This model converts text into dense vector embeddings.\n",
    "\n",
    "# Embeddings capture semantic meaning (not just exact words).\n",
    "\n",
    "# Itâ€™s fast and lightweight.\n",
    "# Internally:\n",
    "# \"father name\" â†’ [0.23, -0.14, ..., 0.01] (384-dim vector)\n",
    "# \"Whatâ€™s your dad's name?\" â†’ similar vector\n",
    "# 3. Read and Parse CSV\n",
    "# Each row in the CSV maps Field(s) â†’ Value (response).\n",
    "# 6. User Input Flow\n",
    "\n",
    "# Comma-separated synonyms like:\n",
    "# \"father name, dad name, papa\" are split and preprocessed.\n",
    "\n",
    "# Preprocess: Extract Field Variants\n",
    "# for row in df:\n",
    "#     variants = field_str.split(\",\")\n",
    "#     for v in variants:\n",
    "#         field_variants.append(v.lower().strip())\n",
    "#         field_map[v.lower()] = value\n",
    "# field_variants = [\"father name\", \"dad name\", \"papa\", \"your name\", ...]\n",
    "# field_map = {\n",
    "#   \"father name\": \"Anshul Sharma\",\n",
    "#   \"papa\": \"Anshul Sharma\",\n",
    "#   ...\n",
    "# }\n",
    "\n",
    "# 5. Generate Embeddings\n",
    "# field_embeddings = model.encode(field_variants, convert_to_tensor=True)\n",
    "# Each field becomes a semantic vector:\n",
    "# \"father name\" â†’ tensor([0.12, -0.55, ..., 0.33])\n",
    "\n",
    "# 6. User Input Flow\n",
    "# def get_response(user_input, ...)\n",
    "# Internally:\n",
    "\n",
    "# a. Correct Typos\n",
    "# correct_typos(\"Dadâ€™s n@me!\") â†’ \"dads name\"\n",
    "# b. Expand with Synonyms\n",
    "# expand_with_synonyms(\"dads name\") â†’ \"dads name dad father\"\n",
    "\n",
    "# c. Encode Input\n",
    "# query_embedding = model.encode(expanded_input)\n",
    "# d. Computes similarity between query and each field:\n",
    "# \"What's your dadâ€™s name?\" vs [\"father name\", \"your name\", ...]\n",
    "# â†’ cosine scores like [0.87, 0.22, 0.04, ...]\n",
    "\n",
    "# e. Fuzzy Score\n",
    "# fuzz.token_set_ratio(\"whatâ€™s your dadâ€™s name\", \"father name\") â†’ 80\n",
    "\n",
    "# f. Threshold-Based Match\n",
    "# if similarity > 0.55 or fuzzy_score > 55:\n",
    "#     return correct response\n",
    "# else:\n",
    "#     return \"Sorry, Iâ€™m not sure...\"\n",
    "\n",
    "# 7. Save Artifacts for Flask\n",
    "\n",
    "# pickle.dump(df, field_variants, field_map)\n",
    "# torch.save(field_embeddings)\n",
    "# Avoid recomputing embeddings when deploying.\n",
    "\n",
    "# Use this in your Flask app without repeating preprocessing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2103bf3-dc98-461b-987b-52f1a8f5bfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | ğŸ”¢ Step | ğŸ§© Component             | ğŸ“ Description                         | ğŸ§  Internal Operation                                                      | ğŸ§ª Example                                            |\n",
    "# | ------- | ------------------------ | -------------------------------------- | -------------------------------------------------------------------------- | ----------------------------------------------------- |\n",
    "# | 1ï¸âƒ£     | **Install Packages**     | Installs required libraries            | Downloads and sets up `sentence-transformers`, `rapidfuzz`, and `nltk`     | `pip install -q sentence-transformers rapidfuzz nltk` |\n",
    "# | 2ï¸âƒ£     | **Import Modules**       | Loads Python packages                  | Imports for NLP, embedding, fuzzy logic, and preprocessing                 | `import pandas as pd`, `import torch`, etc.           |\n",
    "# | 3ï¸âƒ£     | **Download WordNet**     | Enables synonym expansion              | Downloads NLTK corpora: `wordnet` & `omw-1.4`                              | `nltk.download('wordnet')`                            |\n",
    "# | 4ï¸âƒ£     | **Load CSV File**        | Loads personal Q\\&A data               | Reads `amibot.csv` into a DataFrame with 'Field' and 'Value' columns       | CSV sample: `father name, Anshul Sharma`              |\n",
    "# | 5ï¸âƒ£     | **Parse Field Variants** | Splits Field into multiple query forms | For each comma-separated variation in \"Field\", create mappings             | `\"father name, dad name\"` â†’ 2 keys                    |\n",
    "# | 6ï¸âƒ£     | **Build Mapping Dicts**  | Store phrases and answers              | `field_variants = []` stores queries, `field_map = {}` maps to values      | `\"dad name\" â†’ Anshul Sharma`                          |\n",
    "# | 7ï¸âƒ£     | **Generate Embeddings**  | Semantic vectors for field variants    | Converts all `field_variants` to dense vectors using `SentenceTransformer` | `\"father name\" â†’ [0.23, -0.54, ..., 0.11]`            |\n",
    "# | 8ï¸âƒ£     | **Typo Correction**      | Pre-clean user input                   | Removes symbols and lowercases the input via regex                         | `\"Dadâ€™s name?\" â†’ \"dads name\"`                         |\n",
    "# | 9ï¸âƒ£     | **Synonym Expansion**    | Enhances semantic reach                | Adds 1â€“2 synonyms from WordNet to each word                                | `\"dad\"` â†’ `\"dad father papa\"`                         |\n",
    "# | ğŸ”Ÿ      | **User Input Encoding**  | Transforms input to embedding          | Uses model to encode expanded user input                                   | `\"Who is your dad?\" â†’ tensor`                         |\n",
    "# | 1ï¸âƒ£1ï¸âƒ£  | **Cosine Similarity**    | Semantic comparison                    | Measures angle between input vector and all stored field vectors           | `cos_sim = 0.82 with \"father name\"`                   |\n",
    "# | 1ï¸âƒ£2ï¸âƒ£  | **Fuzzy Matching**       | Textual string similarity              | Uses `fuzz.token_set_ratio` to score rough matches                         | `\"Who is your dad?\" vs \"father name\" â†’ 76`            |\n",
    "# | 1ï¸âƒ£3ï¸âƒ£  | **Response Selection**   | Final decision on best match           | Chooses highest score above thresholds: `cos_sim > 0.55 or fuzzy > 55`     | âœ… Match: `\"father name\" â†’ Anshul Sharma\"`             |\n",
    "# | 1ï¸âƒ£4ï¸âƒ£  | **Fallback Message**     | Handles low-match inputs               | Suggests closest match or asks user to rephrase                            | `\"ğŸ¤– Sorry, Iâ€™m not sure...\"`                         |\n",
    "# | 1ï¸âƒ£5ï¸âƒ£  | **Save Artifacts**       | Save all required objects              | Dumps model outputs and mappings to `amibot_data/` folder for Flask        | `field_embeddings.pt`, `field_map.pkl`                |\n",
    "# | 1ï¸âƒ£6ï¸âƒ£  | **Interactive Testing**  | Run in Jupyter loop                    | Continuously prompt for input, display match & answer                      | `input(\"Ask AmiBot: \")`                               |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc92fe00-dc24-41b9-9026-571c010b595f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | ğŸ” User Input             | ğŸ¯ Cleaned Input        | ğŸ§  Expanded Input                   | ğŸ”— Best Match    | ğŸ“ Cosine Sim | ğŸ”¤ Fuzzy Score | âœ… Final Response            |\n",
    "# | ------------------------- | ----------------------- | ----------------------------------- | ---------------- | ------------- | -------------- | --------------------------- |\n",
    "# | \"Whatâ€™s your dadâ€™s name?\" | `whats your dads name`  | `whats your dads name dad father`   | `father name`    | 0.87          | 78             | `Anshul Sharma`             |\n",
    "# | \"Tell me your birthday\"   | `tell me your birthday` | `tell me your birthday natal birth` | `dob`            | 0.74          | 68             | `09 September 1996`         |\n",
    "# | \"Favourite dish?\"         | `favourite dish`        | `favourite dish food meal`          | `favourite food` | 0.51          | 43             | `ğŸ¤– Sorry, please rephrase` |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c125251-3dae-40b9-8518-1417c558ce33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | ğŸ“ File               | ğŸ“„ Format      | ğŸ§  Contents                           |\n",
    "# | --------------------- | -------------- | ------------------------------------- |\n",
    "# | `df.pkl`              | Pickle         | Original CSV DataFrame                |\n",
    "# | `field_variants.pkl`  | Pickle         | All phrases extracted from 'Field'    |\n",
    "# | `field_map.pkl`       | Pickle         | Maps each variant â†’ Value             |\n",
    "# | `field_embeddings.pt` | PyTorch Tensor | Vector representation of all variants |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c3862d4-22a9-4726-af6c-d1834c70dca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | Setting               | Description                                 | Recommendation                    |\n",
    "# | --------------------- | ------------------------------------------- | --------------------------------- |\n",
    "# | `threshold = 0.55`    | Minimum cosine similarity to consider match | Lower to 0.5 for broader matches  |\n",
    "# | `fuzz_threshold = 55` | Minimum fuzzy ratio for textual match       | Keep above 50 to avoid false hits |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "683f0bf5-aca5-41a2-8ace-0c6a5206b28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "# â”‚           START AMIBOT SYSTEM              â”‚\n",
    "# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "#                   â”‚\n",
    "#                   â–¼\n",
    "# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "# â”‚ ğŸ”„ Load CSV File (amibot.csv)              â”‚\n",
    "# â”‚ - Columns: 'Field', 'Value'                â”‚\n",
    "# â”‚ - Example: \"father name, dad name\", \"Anshul Sharma\" â”‚\n",
    "# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "#                   â”‚\n",
    "#                   â–¼\n",
    "# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "# â”‚ ğŸ”„ Parse and Preprocess Fields              â”‚\n",
    "# â”‚ - Split comma-separated fields             â”‚\n",
    "# â”‚ - Store in:                                â”‚\n",
    "# â”‚     â€¢ field_variants (list of queries)     â”‚\n",
    "# â”‚     â€¢ field_map (dict: query â†’ answer)     â”‚\n",
    "# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "#                   â”‚\n",
    "#                   â–¼\n",
    "# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "# â”‚ âš™ï¸ Encode All field_variants Using Model    â”‚\n",
    "# â”‚ - SentenceTransformer(\"all-MiniLM-L6-v2\")  â”‚\n",
    "# â”‚ - Convert each query to semantic vector    â”‚\n",
    "# â”‚ - Save as: field_embeddings (tensor list)  â”‚\n",
    "# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "#                   â”‚\n",
    "#                   â–¼\n",
    "# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "# â”‚ ğŸ’¾ Save Artifacts to Disk                   â”‚\n",
    "# â”‚ - df.pkl, field_map.pkl, field_variants.pklâ”‚\n",
    "# â”‚ - field_embeddings.pt                      â”‚\n",
    "# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# â–¶ï¸ SYSTEM IS READY â€” USER ENTERS A QUERY BELOW:\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "#                   â”‚\n",
    "#                   â–¼\n",
    "# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "# â”‚ ğŸ§ USER INPUTS QUESTION (e.g., â€œDadâ€™s name?â€) â”‚\n",
    "# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "#                   â”‚\n",
    "#                   â–¼\n",
    "# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "# â”‚ ğŸ”§ Step 1: Preprocess Input                  â”‚\n",
    "# â”‚ - Lowercase                                 â”‚\n",
    "# â”‚ - Remove punctuation and extra whitespace   â”‚\n",
    "# â”‚ â†’ \"Dadâ€™s name?\" â†’ \"dads name\"               â”‚\n",
    "# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "#                   â”‚\n",
    "#                   â–¼\n",
    "# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "# â”‚ ğŸ”§ Step 2: Synonym Expansion (WordNet)      â”‚\n",
    "# â”‚ - For each word in input:                  â”‚\n",
    "# â”‚     â€¢ Add top 1â€“2 synonyms                 â”‚\n",
    "# â”‚ â†’ \"dads name\" â†’ \"dads name father dad\"     â”‚\n",
    "# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "#                   â”‚\n",
    "#                   â–¼\n",
    "# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "# â”‚ ğŸ”§ Step 3: Encode Expanded Input            â”‚\n",
    "# â”‚ - Use same SentenceTransformer model       â”‚\n",
    "# â”‚ - Generate semantic embedding              â”‚\n",
    "# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "#                   â”‚\n",
    "#                   â–¼\n",
    "# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "# â”‚ ğŸ” Step 4: Semantic Comparison              â”‚\n",
    "# â”‚ - Cosine similarity between user input &   â”‚\n",
    "# â”‚   each field_variant embedding             â”‚\n",
    "# â”‚ â†’ Get best_match, best_score               â”‚\n",
    "# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "#                   â”‚\n",
    "#                   â–¼\n",
    "# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "# â”‚ ğŸ”¤ Step 5: Fuzzy String Matching            â”‚\n",
    "# â”‚ - Compare original input vs. best_match    â”‚\n",
    "# â”‚ - Use RapidFuzz `token_set_ratio()`        â”‚\n",
    "# â”‚ â†’ Get fuzzy_score                          â”‚\n",
    "# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "#                   â”‚\n",
    "#                   â–¼\n",
    "# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "# â”‚ ğŸ” Step 6: Check Match Thresholds           â”‚\n",
    "# â”‚ - If best_score â‰¥ 0.55  OR                 â”‚\n",
    "# â”‚   fuzzy_score â‰¥ 55                         â”‚\n",
    "# â”‚   â†’ Proceed with best_match                â”‚\n",
    "# â”‚ - Else â†’ Go to fallback response           â”‚\n",
    "# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "#       â”‚                            â”‚\n",
    "#       â–¼                            â–¼\n",
    "# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "# â”‚ âœ… MATCH FOUND      â”‚    â”‚ âŒ NO CONFIDENT MATCH       â”‚\n",
    "# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "#       â”‚                            â”‚\n",
    "#       â–¼                            â–¼\n",
    "# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "# â”‚ ğŸ” Step 7: Retrieve Answer from field_map   â”‚\n",
    "# â”‚ - Lookup value using best_match            â”‚\n",
    "# â”‚ - Example: \"father name\" â†’ \"Anshul Sharma\" â”‚\n",
    "# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "#       â”‚                            â”‚\n",
    "#       â–¼                            â–¼\n",
    "# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "# â”‚ ğŸ’¬ Return Response:         â”‚   â”‚ ğŸ’¬ Fallback:                           â”‚\n",
    "# â”‚   âœ… Matched: â€˜father nameâ€™ â”‚   â”‚   ğŸ¤– Sorry, Iâ€™m not sure what you meantâ”‚\n",
    "# â”‚   ğŸ‘‰ Anshul Sharma          â”‚   â”‚   ğŸ’¡ Suggested closest: â€˜father nameâ€™ â”‚\n",
    "# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "#                   â”‚\n",
    "#                   â–¼\n",
    "# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "# â”‚ ğŸ” Loop: Wait for Next User Query or Exit   â”‚\n",
    "# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb062ab9-4159-422d-91cd-4ffbc4df5f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | ğŸ”¢ Index | ğŸ§¾ File               | ğŸ“¦ Format         | ğŸ“Œ Contents                                                                     | ğŸ§  Purpose                                                                                | ğŸ“‚ Example                                                                                  |\n",
    "# | -------- | --------------------- | ----------------- | ------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------- |\n",
    "# | 1ï¸âƒ£      | `df.pkl`              | Pickled DataFrame | A full table mapping each **field** (e.g., `Name`) to its **response**          | Used to show all available knowledge, help with UI listing, manual lookup, or export      | `{\"field\": \"Name\", \"value\": \"Amritanshu Mishra\"}`                                           |\n",
    "# | 2ï¸âƒ£      | `field_map.pkl`       | Pickled dict      | Dictionary mapping every **user variant** to a **canonical field**              | Enables the bot to map fuzzy or alternative inputs to a consistent, known response source | `{\"your name\": \"Name\", \"who are you\": \"Name\"}` maps both to the `\"Name\"` field              |\n",
    "# | 3ï¸âƒ£      | `field_variants.pkl`  | Pickled list      | A list of **all accepted phrases** or variants asked by users                   | Used as the raw text input to create sentence embeddings or apply fuzzy matching          | `[\"your name\", \"what's your full name\", \"who are you\", \"tell me your name\"]`                |\n",
    "# | 4ï¸âƒ£      | `field_embeddings.pt` | PyTorch tensor    | A tensor with **vectorized embeddings** (e.g., SentenceTransformer) of variants | Allows fast **cosine similarity search** when user input doesnâ€™t exactly match a variant  | Embedding for \"what's your full name\" stored as a 384-dim vector to match to `\"Name\"` field |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
